{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><strong>Sistem Temu Kembali Informasi</strong><br />\n",
    "<strong><font color=\"blue\">Semester Gasal T.A. 2020/2021</font></strong><br />\n",
    "</center>\n",
    "\n",
    "<strong>Outline pertemuan minggu ke-3</strong><br />\n",
    "<li> Membaca dokumen dari file </li>\n",
    "<li> Representasi vektor </li>\n",
    "<li> Pembobotan</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membaca dokumen dari file\n",
    "<p> Untuk membaca dokumen dari file dapat dilakukan dengan berbagai macam cara, bergantung pada format dari dokumen tersebut </p>\n",
    "\n",
    "<p><img alt=\"\" src=\"figures/2_importing_Files.jpg\" style=\"height:400px; width:510px\" /><br />\n",
    "[<a href=\"http://www.clearcounsel.com/what-happens-to-your-digital-property-after-you-die/\" target=\"_blank\"><strong>Image Source</strong></a>]</p>\n",
    "\n",
    "<p> Berikut ini merupakan list library untuk memparsing dokumen dalam berbagai format </p>\n",
    "<p>* <a href=\"https://textract.readthedocs.io/en/stable/&amp;nbsp\" target=\"_blank\">https://textract.readthedocs.io/</a> <img alt=\"\" src=\"figures/2_textract.png\" style=\"height: 239px; width: 600px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dokumen dengan format .txt\n",
    "import os\n",
    "\n",
    "src_name = \"the_matrix_synopsis.txt\"\n",
    "src_path = os.path.join(\"data\", src_name)\n",
    "\n",
    "docs = list()\n",
    "with open(src_path, 'r', encoding=\"utf-8\") as fin:\n",
    "    # membaca seluruh isi dari dokumen\n",
    "    data = fin.readlines()\n",
    "    \n",
    "    # menghilangkan newline (\"\\n\") dan baris yang kosong\n",
    "    for d in data:\n",
    "        d_strip = d.strip()\n",
    "        \n",
    "        if d_strip:\n",
    "            docs.append(d_strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengecek banyaknya dokumen (note: 1 dokumen = 1 baris)\n",
    "print(\"Panjang dokumen: \", len(docs))\n",
    "\n",
    "# Mengakses isi dari dokumen dengan indeks 1\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dokumen dengan format .csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "src_name = \"data_tweet.csv\"\n",
    "src_path = os.path.join(\"data\", src_name)\n",
    "\n",
    "dff = pd.read_csv(src_path)\n",
    "\n",
    "print(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Json-Files\">Json Files</h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>Populer digunakan untuk data dari Media Sosial dan NoSQL</li>\n",
    "\t<li>Portable: File Json memuat nama variabel dan nilainya (tidak seperti XML)</li>\n",
    "\t<li>Plain Text</li>\n",
    "\t<li>Schemaless: Setiap record tidak harus memiliki jumlah field yang tetap seperti csv</li>\n",
    "\t<li>JSON isomorfis dengan &quot;Dictionary&quot; di Python</li>\n",
    "\t<li>Contoh struktur file json:</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"figures/json.png\" style=\"width: 200px; height: 211px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dokumen dengan format .json\n",
    "import json\n",
    "\n",
    "src_name = \"contoh.json\"\n",
    "src_path = os.path.join(\"data\", src_name)\n",
    "\n",
    "with open(src_path, 'r', encoding=\"utf-8\", errors='ignore') as fin:\n",
    "    data = json.load(fin)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca teks dari halaman website\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "URL = \"https://www.its.ac.id/informatika/fasilitas/laboratorium/laboratorium-komputasi-cerdas-dan-visi/\"\n",
    "doc = urllib.request.urlopen(URL).read()\n",
    "doc = bs(doc, 'lxml').text\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Membaca data dari modul</h3\n",
    "<p>Contoh dataset dokumen yang cukup tenar: &quot;20 NewsGroup&quot;</p>\n",
    "\n",
    "<img alt=\"\" src=\"figures/6_20News.jpg\" style=\"height: 300px ; width: 533px\" />\n",
    "<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups\" target=\"_blank\">http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups</a></p>\n",
    "\n",
    "<p><strong>Categories </strong>=&nbsp;</p>\n",
    "<pre>\n",
    "[&#39;alt.atheism&#39;, &#39;comp.graphics&#39;, &#39;comp.os.ms-windows.misc&#39;, &#39;comp.sys.ibm.pc.hardware&#39;, &#39;comp.sys.mac.hardware&#39;,\n",
    " &#39;comp.windows.x&#39;, &#39;misc.forsale&#39;, &#39;rec.autos&#39;, &#39;rec.motorcycles&#39;, &#39;rec.sport.baseball&#39;, &#39;rec.sport.hockey&#39;,\n",
    " &#39;sci.crypt&#39;, &#39;sci.electronics&#39;, &#39;sci.med&#39;, &#39;sci.space&#39;, &#39;soc.religion.christian&#39;, &#39;talk.politics.guns&#39;,\n",
    " &#39;talk.politics.mideast&#39;, &#39;talk.politics.misc&#39;, &#39;talk.religion.misc&#39;]</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca teks dari modul\n",
    "# note: butuh koneksi internet\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['sci.med', 'talk.politics.misc',  'rec.autos']\n",
    "data = fetch_20newsgroups(subset='train', categories=categories,remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agar tidak perlu mendownload kembali data, ada baiknya disimpan \n",
    "# jika dibutuhkan tinggal membacanya dari drive\n",
    "# data dapat disimpan ke dalam bentuk pickle\n",
    "import pickle\n",
    "\n",
    "dst_name = \"20newsgroups.pickle\"\n",
    "dst_path = os.path.join(\"data\", dst_name)\n",
    "\n",
    "# wb = write binary\n",
    "# w = write\n",
    "# rb = read binary\n",
    "# r = read\n",
    "with open(dst_path, 'wb') as fout:\n",
    "    pickle.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca data dari pickle\n",
    "\n",
    "src_name = dst_name\n",
    "src_path = os.path.join(\"data\", src_name)\n",
    "\n",
    "with open(src_path, 'rb') as fin:\n",
    "    data_pckl = pickle.load(fin)\n",
    "\n",
    "data_pckl.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_pckl.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representasi vektor\n",
    "\n",
    "<ul>\n",
    "    <li>Data teks tidak dapat secara langsung dianalisis dengan model statistik/ data mining</li>\n",
    "    <li>Data teks terlebih dahulu harus diolah melalui tahapan pre-processing dan kemudian direpresentasikan ke dalam bentuk yang lebih sederhana (vektor) agar dapat dengan mudah untuk diolah</li>\n",
    "    <li>Akan tetapi perubahan data ke dalam bentuk yang lebih sederhana dapat berakibat pada hilangnya beberapa informasi dari data tersebut. Contohnya pada metode <strong> bag-of-words </strong> informasi urutan antar kata hilang </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vector Space Model (VSM) </h3>\n",
    "<p> VSM merepresentasikan sebuah kata ke dalam bentuk vektor dalam suatu dimensi spasial. </p>\n",
    "\n",
    "<p><img alt=\"\" src=\"figures/vsm.png\" style=\"width: 300px; height: 213px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Contoh representasi vektor antara term dengan dokumen: </h4>\n",
    "<p><img alt=\"\" src=\"figures/3_Bentuk umum representasi dokumen.JPG\" style=\"height: 294px ; width: 620px\" /></p>\n",
    "\n",
    "<p><img alt=\"\" src=\"figures/vsm_matrix.png\" style=\"width: 500px; height: 283px;\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh pembentukan representasi vektor dengan perhitungan frekuensi (VSM-TF)\n",
    "# dapat menggunakan library CountVectorizer pada sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> TF.IDF-Term Weighting </h4>\n",
    "<ul>\n",
    "    <li> Pada representasi vektor sebelumnya nilai antar term dengan dokumen hanya berupa frekuensi kemunculan saja </li>\n",
    "    <li> Nilai antar term dengan dokumen dapat digantikan dengan bobot TF.IDF </li>\n",
    "    <li> TF (Term Frequency) menghitung frekuensi dari suatu kata pada dokumen; sementara IDF (Inverse Document Frequency) menghitung nilai informatif dari suatu kata berdasarkan tingkat kemunculannya antar dokumen </li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"figures/3_tfidf logic.jpg\" style=\"height:359px; width:638px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Rumus perhitungan TFIDF </h4>\n",
    "<p><img alt=\"\" src=\"figures/3_rumus tfidf.png\" style=\"height:370px; width:367px\" /></p>\n",
    "\n",
    "<p><img alt=\"\" src=\"figures/3_variant tfidf.png\" style=\"height:300px; width:955px\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh pembentukan representasi vektor dengan TFIDF (VSM-TFIDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(corpus)\n",
    "print(vectorizer_tfidf.get_feature_names())\n",
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh pembentukan representasi vektor dengan binary 0 atau 1 (VSM-binary)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "vectorizer_binary = CountVectorizer(binary=True)\n",
    "X_binary = vectorizer_binary.fit_transform(corpus)\n",
    "print(vectorizer_binary.get_feature_names())\n",
    "print(X_binary.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 1:</font></h3>\n",
    "\n",
    "<p> Ubahlah data dari 20newsgroup dataset yang telah disimpan dalam bentuk pickle ke dalam representasi vektornya\n",
    "<ul>\n",
    "    <li> VSM binary </li>\n",
    "    <li> VSM TF </li>\n",
    "    <li> VSM TFIDF </li>\n",
    "</ul>\n",
    "\n",
    "<p> Apakah ukuran matriks yang terbentuk dari ketiga VSM tersebut sama? </p>\n",
    "<p> Apakah baris kosong berpengaruh terhadap ukuran matriks yang terbentuk? </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerjakan latihan 1 pada cell berikut ini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom TFIDF\n",
    "* Menurut http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "* default formula tf-idf yang digunakan sk-learn adalah:\n",
    "* $tfidf = tf * log(\\frac{N}{df+1})$ ==> Smooth IDF\n",
    "* namun kita merubahnya menjadi:\n",
    "* $tfidf = tf * log(\\frac{N}{df})$ ==> Non Smooth IDF\n",
    "* $tfidf = (1+log(tf)) * log(\\frac{N}{df+1})$ ==> sublinear_tf, Smooth IDF\n",
    "* $tfidf = (1+log(tf)) * log(\\frac{N}{df})$ ==> sublinear_tf, Non Smooth IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "'This is the first document.',\n",
    "'This document is the second document.',\n",
    "'And this is the third one.',\n",
    "'Is this the first document?',\n",
    "]\n",
    "tfidf_vectorizer = TfidfVectorizer(smooth_idf= False, sublinear_tf=True, lowercase=True)\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "print(tfidf.shape) # Sama\n",
    "print(tfidf[0].data) # Hanya data ini yg berubah\n",
    "print(tfidf[0].indices) # Letak kolomnya = tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id=\"Zipf's-Law:--&quot;power-law&quot;-:\">Zipf&#39;s Law: &quot;power law&quot; :</h4>\n",
    "\n",
    "<img alt=\"\" src=\"figures/zipf.png\" style=\"width: 456px; height: 270px;\" />\n",
    "<ul>\n",
    "\t<li><a href=\"https://plus.maths.org/content/mystery-zipf\" target=\"_blank\">https://plus.maths.org/content/mystery-zipf</a></li>\n",
    "\t<li><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4176592/\" target=\"_blank\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4176592/</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency filtering di VSM\n",
    "# Menghilangkan term yg memiliki frequency kemunculan di banyak dokumen > threshold \n",
    "# dan term yang memiliki frequency kemunculan antar dokumen < threshold\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_1 = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "tfidf_vectorizer_filter = TfidfVectorizer(max_df=0.75, min_df=1)\n",
    "tfidf_2 = tfidf_vectorizer_filter.fit_transform(corpus)\n",
    "\n",
    "print(tfidf_1.shape)\n",
    "print(tfidf_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 2:</font></h3>\n",
    "\n",
    "<ul>\n",
    "    <li> Lakukan filtering pada VSM dari 20newsgroup dataset </li> \n",
    "    <li> Diskusikanlah, mengapa menghilangkan term yang memiliki frekuensi kemunculan tinggi antar dokumen?</li>\n",
    "    <li> Mengapa menghilangkan term yang memiliki frekuensi kemunculan rendah antar dokumen? </li>\n",
    "    <li> Mengapa perlu melakukan filtering berdasarkan frekuensi? </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerjakan latihan 2 pada cell berikut ini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model VSM dapat dipergunakan untuk N-gram\n",
    "# Bermanfaat untuk menangkap term yang berupa frase\n",
    "tfidf_vectorizer_ngram = TfidfVectorizer(ngram_range = (1,2))\n",
    "tfidf_ngram = tfidf_vectorizer_ngram.fit_transform(corpus)\n",
    "\n",
    "print(\"=====Without N-gram=====\")\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "print(\"=====With N-gram=====\")\n",
    "print(tfidf_vectorizer_ngram.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 3:</font></h3>\n",
    "\n",
    "<ul>\n",
    "    <li> Diskusikanlah, apakah n-gram efektif untuk menangkap term yang berupa frase? apakah hasil yang diperoleh dari n-gram SVM sudah memuaskan?\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kerjakan latihan 3 pada cell berikut ini"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('stki': conda)",
   "display_name": "Python 3.7.9 64-bit ('stki': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e57d1b1b8ff6275b181ee0a3a4d742460414aec1e5ac6279440be3a6e7672b9e"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}